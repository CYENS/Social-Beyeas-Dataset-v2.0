# Social-Beyeas-Dataset-v2.0
Researchers of Web and social media rely extensively on image analysis tools to understand users' sharing behaviors and engagement with content on the large scale. However, it has been made clear over the past years that there are disparities in the way that these tools treat images depicting people from different social groups. Previously, we released the Social B(eye)as Dataset, consisting of machine- and human-generated descriptions on a controlled set of people images without context. This resource allows researchers to compare the behaviors of taggers and humans systematically. We now update this, with a process that imposes the people-images onto backgrounds. The current release uses four stereotypically "feminine" and four "masculine" contexts. Thus, it enables us to consider the possible influences upon the gender inferences that are made by tagging algorithms. We also provide an updated typology of tags used by the six proprietary taggers as well as initial analyses. Our methodology for imposing semi-transparent images onto background images is publicly available, allowing others to repeat the process with other combinations of images for various research topics. (2020-01-15)

# Citation
Barlas, Pinar; Kyriakou, Kyriakos; Guest, Olivia; Kleanthous, Styliani; Otterbacher, Jahna, 2020, "Social B(eye)as Dataset v2.0", https://doi.org/10.7910/DVN/4W5GOW, Harvard Dataverse, V2, UNF:6:XvvGENX+m9ZGaOAFbwODqQ== [fileUNF]

This work was originally published on Harvard Dataverse: https://doi.org/10.7910/DVN/4W5GOW
